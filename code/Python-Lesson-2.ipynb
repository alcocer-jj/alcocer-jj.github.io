{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<h1>\n",
    "Python for Social Science Workshop - Lesson 2\n",
    "</h1>\n",
    "</div>\n",
    "<br />\n",
    "<div align=\"center\">\n",
    "<h3>\n",
    "Jose J Alcocer\n",
    "</h3>\n",
    "</div>\n",
    "<br />\n",
    "<div align=\"center\">\n",
    "<h4>\n",
    "April 11, 2023\n",
    "</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "****"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working With NumPy, Pandas, Matplot, and Seaborn <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "## 1.0 Setting up the environment <br>\n",
    "This lesson will be dense, as we will cover the most basic libraries and functions that are building blocks of the work we do as social scientists. Let's begin this lesson by importing the proper libraries we will be using throughout the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Loops and Conditional Statements <br>\n",
    "\n",
    "Like in R, Python is able to handle several types of loops and conditional statements, which allow us to automate tasks and create more efficient code. <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "### 1.1.1 For Loops <br>\n",
    "\n",
    "With loops, it is possible to iterate over lists or a range of numbers alike to automate a task. We can see a few of these examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop using a list we create within the loop\n",
    "for x in ['Apples','Bananas','Oranges','Pears','Pineapples','Mangoes','Grapefruits','Cantaloupes']:\n",
    "    print('I like to eat '+x +'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop using a list that already exists\n",
    "list1 = list(random.sample(range(1,100),50))\n",
    "\n",
    "# If you do not specify print here, the loop will still perform, but you will not see an output\n",
    "for i in list1:\n",
    "    print(i*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop to using a range in order to add values to a list\n",
    "\n",
    "# Creating a list\n",
    "list2 = []\n",
    "\n",
    "# For loop that says for every i from 0 to 9, multiply each value by 10 and append it to the list created. This is similar to the code used in R where you name the object and place a [i] next to the name of it\n",
    "for i in range(0,10):\n",
    "    list2.append(i*10)\n",
    "\n",
    "print(list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 While Loops <br>\n",
    "\n",
    "Like in R, while loops are a bit more efficient, as they keep on running until the condition you state is met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a while loop to append a list\n",
    "\n",
    "# Creating an object\n",
    "x = 5\n",
    "# Creating a list\n",
    "y = []\n",
    "\n",
    "# Telling python while the object is smaller than 50, append the object, x*10, to the list and add 5 to the initial object each time this task is successfully completed\n",
    "while x < 50:\n",
    "    y.append(x*10)\n",
    "    print(x)\n",
    "    x=x+5\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 If and Else Statements <br>\n",
    "\n",
    "If-Else statements are conditional arguements that tell Python to run under different set of conditions. If the first condition is met, then do one task; if not, do another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic If-Else statement\n",
    "x = 0\n",
    "\n",
    "if x!=0:\n",
    "    print(1/x)\n",
    "else:\n",
    "    print('No reciprocal for 0.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic If-Else statement with different x value\n",
    "x = 2\n",
    "\n",
    "if x!=0:\n",
    "    print(1/x)\n",
    "else:\n",
    "    print('No reciprocal for 0.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 Elif (Else if) in If-Else Statements <br>\n",
    "\n",
    "'Elif' is an additional operator you can give to an if-else statement. It allows you to create more conditions and more tasks to do if two are not enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an object to represent Democratic presidential vote in a general election\n",
    "district_vote = 53\n",
    "\n",
    "if district_vote in range(40,61):\n",
    "    print('This district is competitive')\n",
    "elif district_vote in range(0,40):\n",
    "    print('This is a safe Republican district')\n",
    "else: print('This is a safe Democratic district')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an object to represent Democratic presidential vote in a general election\n",
    "district_vote = 61\n",
    "\n",
    "if district_vote in range(40,61):\n",
    "    print('This district is competitive')\n",
    "elif district_vote in range(0,40):\n",
    "    print('This is a safe Republican district')\n",
    "else: print('This is a safe Democratic district')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also possible to use nested loops and conditional statements in Python. For the sake of time constraints, here is just one example, but you can go on this [link](https://pynative.com/python-nested-loops/) to learn more about how to create them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the else argument within a while loop\n",
    "counter = 0\n",
    "\n",
    "while counter < 10: # part of while loop\n",
    "    # loop will end/break once counter hits 10\n",
    "    if counter == 10: # part of if-else\n",
    "        break\n",
    "    print('Inside loop') # part of while loop\n",
    "    counter = counter + 1\n",
    "else: # part of if-else\n",
    "    print('Inside else')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 NumPy (Numerical Python) Library <br>\n",
    "\n",
    "So far, we learned about lists and tuples and how useful they are for working with multiple numeric and non-numeric observations in Python. However, what happens when you want to work large objects or even with two-dimensional objects (i.e., objects that contain rows and columns)? Native Pyton lists and tuples, while good, are not as efficient when you begin working with large amounts of data that might be stacked on top of eachother. That is where NumPy comes in. The NumPy library offers an object called an 'array' that can be stacked and can be used to compute several types of processes in a much faster and efficient manner. The main reason why this is possible is due to the arrays being written in C language, which allows them to be stored in contiguous memory locations within your machine, making them more accessible and easier to manipulate. NumPy also offers several statistical functions that allow us the ability to compute several analyses without having to use additional packages. Learning how NumPy operates is fundamental to being able to work with dataframes (will be discussed in the next section). <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "### 1.2.1 Creating Arrays <br>\n",
    "\n",
    "The syntax for creating arrays is `np.array()`, and it an be used to either convert an existing list or tuple into one, or create one from scratch. It is important to note that unlike lists and tuples, you cannot have multiple data types within an array, so it can either be strings or integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting an existing list to a one dimensional numeric array\n",
    "\n",
    "# Creating a list\n",
    "list1 = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "# Creating an object that converts a list into an array\n",
    "array1 = np.array(list1)\n",
    "# Confirming that it is indeed an array with the type() function; conversely, look at the variables window\n",
    "type(array1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a one dimensional numeric array from scratch\n",
    "\n",
    "array1 = np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "print(array1)\n",
    "print(type(array1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a one dimensional string array\n",
    "array1 = np.array([\"Hi\",\"Hola\",\"Salut\",\"Ciao\",\"Privet\",\"Hallo\",\"Oi\",\"Anyoung\",\"Ahlan\",\"Hej\",\"Hoi\"])\n",
    "\n",
    "print(array1)\n",
    "print(type(array1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a two-dimensional numeric array\n",
    "\n",
    "# Brackets tell python to separate the arrays and make them two-dimensional\n",
    "array1 = np.array([[1,2,3,4,5,6,7,8,9,10],\n",
    "                  [11,12,13,14,15,16,17,18,19,20],\n",
    "                   [21,22,23,24,25,26,27,28,29,30]])\n",
    "print(array1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While arrays cannot handle multiple data types, you can coerce Python into allowing you to include different types by telling Python to store all observations as an object. You would not be able to compute calculations with this array, but it is still cool to know you can do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array1 =np.array([[True, False, 'hello'],\n",
    "                  ['apple', 33.7, (0,1)],\n",
    "                  [37,40,50]], dtype=object)\n",
    "print(array1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Indexing Arrays <br>\n",
    "\n",
    "Like lists and tuples, you are able to index specific observations from both one-dimensional and two-dimensional arrays. The indexing mechanism is the same as indexing in R, where the first coordinate refers to the y-axis (rows) and the second coordinate refers to the x-axis (columns). As a reminder, unlike R, Python begins its indexing with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array1 = np.array([[1,2,3,4,5,6,7,8,9,10],\n",
    "                   [11,12,13,14,15,16,17,18,19,20],\n",
    "                   [21,22,23,24,25,26,27,28,29,30]])\n",
    "# Indexing the number that is on the first row, third column\n",
    "print(array1[0,2])\n",
    "\n",
    "# Indexing the number that is on the third row, sixth column\n",
    "print(array1[2,5])\n",
    "\n",
    "# Indexing multiple values - first three values in first row | Python does not include the final value to give it\n",
    "print(array1[0,0:3])\n",
    "\n",
    "# Indexing multiple values - first values from each row | Python does not include the final value to give it\n",
    "print(array1[0:3,0])\n",
    "\n",
    "# Indexing all values from the array\n",
    "print(array1[:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 NumPy Statistics <br>\n",
    "\n",
    "The NumPy library includes functions that allow us to conduct basic statistics. There are three ways to calculate statistics when working with two-dimensional arrays: <br>\n",
    "* Calculating statistics for the entire array;\n",
    "* Calculating statistics for each column (must include 'axis=0' inside the function);\n",
    "* Calculating statistics for each row (must include 'axis=1' inside the function). <br>\n",
    "\n",
    "Basic statistical functions include but are not limited to: <br>\n",
    "* `np.mean()` - calculates mean of an array object\n",
    "* `np.sum()` - calculates sum of an array object\n",
    "* `np.min()` - finds the min value of an array object\n",
    "* `np.max()` finds the max value of an array object\n",
    "* `np.std()` calculates the standard deviation of an array object\n",
    "* `np.median()` - finds the median value of an array object\n",
    "* `np.sort()` - sorts an array object in ascending order\n",
    "* `np.sort()[::-1]` - sorts an array object in descending order\n",
    "* `np.random.random(size= int)` - creates an array with random floats between 0 and 1\n",
    "* `np.random.randint(int,int, size=int)` - creates an array of integers in any shape\n",
    "* `np.random.randn(int)` - creates and returns a sample or samples from the standard normal distribution\n",
    "* `np.random.shuffle()` - modifies the sequence of an array by shuffling it\n",
    "* `np.count-nonzero()` - returns the count of non-zero elements in an array; useful when measuring sparsity\n",
    "\n",
    "<br>\n",
    "\n",
    "The following lines of code will show some examples of these functions and the variations that can be done using the 'axis' arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating array the way we've been doing so\n",
    "array1 = np.array([[1,2,3,4,5,6],\n",
    "                   [7,8,9,10,11,12],\n",
    "                   [13,14,15,16,17,18]])\n",
    "\n",
    "# Creating an array using numpy function arange and reshape functions\n",
    "# You can use multiple functions by simply adding a period '.' so long as it makes sense to do so\n",
    "# the agument is as follows (first number to start on, number to stop at (it will not actually include it), and by how many integers to skip by)\n",
    "# very similar to the `seq()` function in R\n",
    "array1 = np.arange(1,19,1).reshape(3,6)\n",
    "\n",
    "print(array1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finding the mean of the array above\n",
    "\n",
    "# Entire array\n",
    "print('The entire mean of the array is:', np.mean(array1))\n",
    "\n",
    "# Mean of each column in the array - we should get an array of six values\n",
    "print('The mean of each column in the array is:', np.mean(array1, axis=0))\n",
    "\n",
    "# Mean of each row in the array - we should get an array of three values\n",
    "print('The mean of each row in the array is:', np.mean(array1, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finding the sum of the array\n",
    "\n",
    "# Entire array\n",
    "print('The sum of the array is:', np.sum(array1))\n",
    "\n",
    "# Sum of each column in the array - we should get an array of six values\n",
    "print('The sum of each column in the array is:', np.sum(array1, axis=0))\n",
    "\n",
    "# Sum of each row in the array - we should get an array of three values\n",
    "print('The sum of each row in the array is:', np.sum(array1, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finding the median of the array\n",
    "\n",
    "# Entire array\n",
    "print('The median of the array is:', np.median(array1))\n",
    "\n",
    "# Std of each column in the array - we should get an array of six values\n",
    "print('The median of each column in the array is:', np.median(array1, axis=0))\n",
    "\n",
    "# Std of each row in the array - we should get an array of three values\n",
    "print('The median of each row in the array is:', np.median(array1, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sort(array1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating random sample of floats from 0 to 1\n",
    "array1 = np.random.random(size=1000)\n",
    "print(array1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array1 = np.random.randint(0,50, size=50)\n",
    "print(array1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like in R, you can set a seed to ensure same iteration each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(444)\n",
    "array1 = np.random.randint(0,50, size=50)\n",
    "print(array1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Pandas (Panel Python) Library <br>\n",
    "\n",
    "As mentioned above, knowing how NumPy works is essential to programming in Python, as several libraries are built to work on top of NumPy. Pandas is one of those libraries. The Pandas library offers several data structures and operations for manipulating numeric data along with time series. It allows for the importing, creating, managing, and exporting of dataframes, making it the staple library for data science in Python. Pandas allows to create what can be called 'Pandas series' and 'Pandas DataFrames'. For this lesson, our main focus for Pandas will be DataFrames and how to create, import, and manipulate them.  <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "### 1.3.1 Creating a Pandas Series <br>\n",
    "\n",
    "A Pandas series is a simple one-dimensional array that can hold any datatype (e.g., integer, string, float, objects). A Pandas series is nothing more than a single column of data found in an excel sheet. Creating a series is as simple as creating a list, tuple, or one-dimensional array.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PdSeries = pd.Series([1, 2, 3, 4, 5,6,7,8,9,10])\n",
    "\n",
    "print(PdSeries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like NumPy Arrays, a Pandas series can be indexed in using the brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing the third value from the Pandas series\n",
    "PdSeries[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Creating a Pandas DataFrame <br>\n",
    "\n",
    "While one Pandas series may not be any more useful than NumPy arrays, several series can be combined into a Pandas DataFrame. A Pandas DataFrame is a two-dimensional tabular data structure with labeled rows and columns, which is the same as a DataFrame used in R, Excel, Stata, SQL, or SPSS. Creating a Pandas DataFrame is similar to creating a Python Dictionary or a DataFrame in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame\n",
    "\n",
    "df = pd.DataFrame({'Name':[\"Student A\", \"Student B\", \"Student C\"],\n",
    "                          'Year': [\"Third Year\", \"Second Year\", \"Second Year\"],\n",
    "                          'Position':[\"Treasurer\",\"Senator\",\"President\"]})\n",
    "\n",
    "# Using the print function gives you an in-text DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the DataFrame without using the print function gives you an interactive table thanks to Data Spell. This feature is unique to the program and it allows us to view the DataFrame in a new window (Like in R), and even export the DataFrame into a csv file without having to write additional code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create a DataFrame from an existing two-dimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an array that has 10 rows and 5 columns\n",
    "array1 = np.arange(1,100,2).reshape(10,5)\n",
    "\n",
    "# Creating DataFrame and using 'columns' argument to assign names to the columns in DF\n",
    "df = pd.DataFrame(array1, columns=['var1','var2','var3','var4','var5'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also import a dataframe from an existing url that contains a csv file. For this example, we will be importing a csv file from the New York Times containing COVID-19 related cases. [Here](https://www.nytimes.com/interactive/2021/us/covid-cases.html) is the article showing COVID trends online, and [here](https://github.com/nytimes/covid-19-data) is the github repository where this dataset was found. Pandas supports reading different types of files. Here are some examples of those:\n",
    "\n",
    "* `pd.read_csv()` - reads csv files\n",
    "* `pd.read_excel()` - reads excel files\n",
    "* `pd.read_stata()` - reads stata files\n",
    "* `pd.read_sql()` - reads sql database files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading dataframe from a link online\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 Indexing DataFrames <br>\n",
    "\n",
    "Indexing data from a DataFrame can be done in two ways. The first way is to index a DataFrame by calling the name of the variable with the choice of setting a condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing DataFrame to only give us data on the states\n",
    "df['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing DataFrame to only give us data on the states and cases\n",
    "# When indexing multiple variables, we need to include a second set of brackets\n",
    "df[['state','cases']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing DataFrame by slicing/telling Python to get specific rows\n",
    "df[10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.4 Subsetting DataFrames <br>\n",
    "\n",
    "Sometimes, we might only be interested in a particular subset of a DataFrame. Like in R, Pandas allows us to subset data from a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting DataFrame to only give us the states that are california and nothing else\n",
    "df[df['state']=='California']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also subset a DataFrame on negative conditions. This can be done so using the tilde operator `~`. Here, we are telling Python to subset us the DataFrame so it does not include California."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting DataFrame to only give us all the states except California\n",
    "df[~(df['state']=='California')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to make a new DataFrame out of this subset, you simply need to store in a new object. Additionally, if you want to reset the index, you can use the `.reset_index()` function to make the index start from 0 in this newly subsetted DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[~(df['state']=='California')].reset_index()\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subsetting using the 'And' Operator\n",
    "\n",
    "What if you want to subset based on multiple conditions? You can by including the '&' operator and placing the conditions in their own separate parentheses. Here, we are interested in only seeing the days that California had over 500 cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['state']=='California') & (df['cases']>500)].reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, we can use the tilde operator to ensure that we subset a DataFrame on several negative conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv')\n",
    "\n",
    "# Subsetting DataFrame to include all states that are not CA and all cases under 500\n",
    "df = df[~(df['state']=='California') & ~(df['cases']>500)].reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subsetting using the 'Or' Operator <br>\n",
    "\n",
    "Like '&', you can also use the '|' operator and Python will subset based on multiple conditions it has pertaining to one variable of interest. In this example, we are interested in subsetting the DataFrame so it keeps California and New York."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv')\n",
    "\n",
    "df[(df['state']==\"California\") | (df['state']==\"New York\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the '|' operator to include more than two conditions from a variable. Here, we will keep four states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv')\n",
    "\n",
    "df[(df['state']==\"California\") | (df['state']==\"New York\") | (df['state']==\"Washington\") | (df['state']==\"Texas\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.5 Transforming DataFrames <br>\n",
    "\n",
    "Pandas allows us to make changes to DataFrames similar to how we can manipulate DataFrames in R. <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Creating/Replacing New Variables/Columns to DataFrame <br>\n",
    "\n",
    "The following code snippets shows different variations of adding a new variable to the existing DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv')\n",
    "\n",
    "# Creating a new variable\n",
    "df['death/case ratio'] = 0\n",
    "\n",
    "# Like in R, you can use the head() function to give you the first 5 observations\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new variable/replacing a current one with new values; in this case, we will create a variable that calculates the ratio of deaths to cases\n",
    "# Python will calculate what you want it to and will do it per row\n",
    "df['death/case ratio'] = (df['deaths']/df['cases'])\n",
    "\n",
    "# Like in R, you can use the tail() function to get the last 5 observations\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing observations from DataFrame across all columns from the 0th to 2nd observation\n",
    "# Copying a df using the copy(); this ensures that changes are not affected across all dataframes\n",
    "df2 = df.copy()\n",
    "\n",
    "# Telling Python to replace all columns from the 0th row to the 2nd with 1000\n",
    "df2.iloc[0:3,:]=1000\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Telling Python to replace first and second column from the 0th row to the 2nd with 1000\n",
    "df2.iloc[0:3,0:2]='DataFrame'\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Telling Python to replace all observations in the fips column\n",
    "df2.loc[:,'fips']='Python'\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping/Deleting Variables/Columns to DataFrame <br>\n",
    "\n",
    "The following code snippets shows different variations of dropping variables from an existing DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping last variable, death/case ratio\n",
    "## Axis 1 is columns\n",
    "## Inplace True means that these changes will be reflected in the dataframe; False means it will only be reflected in the code snippet output\n",
    "df2.drop('death/case ratio', axis=1, inplace= True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping the first three rows\n",
    "## Axis is 0 for rows\n",
    "df2.drop([0,1,2], axis=0, inplace= True)\n",
    "df2 = df2.reset_index()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping the first 50 rows\n",
    "## Axis is 0 for rows\n",
    "df2.drop(range(0,50), axis=0, inplace= True)\n",
    "df2 = df2.reset_index()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we reset the index, the index that was in place, moves to the dataframe, so we must get rid of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop(['level_0','index'], axis=1, inplace= True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing Variable Data Types in DataFrame <br>\n",
    "\n",
    "Sometimes, you might need to change the type of a variable due to poor formatting or other reasons. Python allows us to change data types using the `.to_numeric()` or `.astype()` functions. The following code snippets shows different variations of changing data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better sense of what data types we have within our DataFrame, we can use the `.dtypes` command to have Python give us this info for each variable. For this example, we will create a new variable that is a string and convert it to an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['var7'] = '0'\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will change the 'var7' variable from an 'object' type to an 'integer' type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['var7'] = df['var7'].astype(int)\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the 'var7' we created is now an integer. We can also turn it back into a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['var7'] = df['var7'].astype(str)\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In DataFrames, a string is categorized as an object, so we know that if it says object, then it is a string type. <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Sorting and Grouping Data <br>\n",
    "\n",
    "Sometimes, you might might want to organize your DataFrame by a particular variable or perform operations across groups. We can do this using the `.sort_values()` and `.groupby()` functions. The `.sort_values()` function can organize your DataFrame by columns of choice, and the `.groupby()` function can perform statistical operations by categorical groups. It can also tabulate data (similar to the `table()` function in R)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group DataFrame by state in ascending order\n",
    "df.sort_values(by=['state'], inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group DataFrame by state in descending order\n",
    "df.sort_values(by=['state'], inplace=True, ascending=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.groupby()` function can be used in combination with other statistical operations to get particular answers that we might have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping DataFrame by state and fips codes to get the total number of observations per state\n",
    "df.groupby(\"state\")['fips'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping DataFrame by state and getting the sum of deaths\n",
    "df.groupby(\"state\")['deaths'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping DataFrame by state and getting the maximum number of deaths per state\n",
    "df.groupby(\"state\")['deaths'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's group by state and year now. When working with time series data, we must always convert our date variables to a format that Python can interpret, 'datetime'. Using a code similar to converting data types, the function `pd.to_datetime()` allows us to convert an existing date variable into a datetime object. From there, we can extract specific parts of the date we are interested in. For this example, we will create a year variable out of the date variable we already have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Data Types of our current DataFrame\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our current data variable is categorized as an object, which does not allow us to use it for anything useful, let's convert it to datetime.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting current date to datetime type\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that date is a datetime object, let's get a year variable out in order to group our DataFrame by state and year.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating year variable out of the date variable\n",
    "df['year'] = df['date'].dt.year\n",
    "\n",
    "# Grouping by state and year to get sum of deaths per year\n",
    "df.groupby(['state','year'])['deaths'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to perform multiple statistical operations, we can use the `.agg()` command to tell Python to place them all in one output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by state and year to get sum of deaths per year, highest amount of deaths per year, and average deaths per state\n",
    "df.groupby(['state','year'])['deaths'].agg(['sum','max','mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating (Rows) and Merging (Columns) Data <br>\n",
    "\n",
    "A final task we will be covering in relation to data handling is appending datasets. Python gives us the `concat()` and `merge()` functions to allow us to combine multiple data sources into a single dataset. Let's use the join function first. <br>\n",
    "\n",
    "Before concatenating or merging anything, we will be creating two new DataFrames out of our covid dataset. We will subset CA and Texas into their own DataFrames, then bring them back together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new df in order to subset it to include CA and TX separately\n",
    "df_ca = df.copy()\n",
    "df_tx = df.copy()\n",
    "\n",
    "# Subsetting df to get CA\n",
    "df_ca = df_ca[df_ca['state']=='California']\n",
    "df_tx = df_tx[df_tx['state']=='Texas']\n",
    "\n",
    "# Subsetting CA to split variables\n",
    "df3 = df_ca[['date','state','cases']].reset_index(drop=True)\n",
    "df4 = df_ca[['date','deaths','year']].reset_index(drop=True)\n",
    "\n",
    "# Sorting new df by date\n",
    "df_ca.sort_values(by=['date'], inplace=True)\n",
    "df_tx.sort_values(by=['date'], inplace=True)\n",
    "df3.sort_values(by=['date'], inplace=True)\n",
    "df4.sort_values(by=['date'], inplace=True)\n",
    "\n",
    "# Resetting index | drop = true ensures we don't have an index variable in the df\n",
    "df_ca = df_ca.reset_index(drop=True)\n",
    "df_tx = df_tx.reset_index(drop=True)\n",
    "df3 = df3.reset_index(drop=True)\n",
    "df4 = df4.reset_index(drop=True)\n",
    "\n",
    "# Dropping unwanted variables\n",
    "df_ca.drop(['death/case ratio','fips','var7'], axis=1, inplace=True)\n",
    "df_tx.drop(['death/case ratio','fips','var7'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are interested in joining two datasets by rows, we will be using the `concat()` function. Setting 'ignore index = True' will tell Python not to create an additional column of an index it dropped as a result of the concatenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_both_states = pd.concat([df_ca, df_tx], ignore_index=True)\n",
    "df_both_states.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to join two datasets based on columns, unlike the concat that joins on rows, we would need to use the `merge()` command that allows to combine datasets horizontally. The `merge()` merges two datasets by keywords (variables). In addition, it comes with a few options for its \"how=\" argument: <br>\n",
    "* \"how = inner\" - it joins only existing pairs\n",
    "* \"how = outer\" - it joins all observations (expect a few NaNs as a result)\n",
    "* \"how = left\" - it joins with the calling dataset's index\n",
    "* \"how = right\" - it joins with the second dataset's index\n",
    "\n",
    "We will be merging with an inner option to ensure that both datasets are matched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df3.merge(df4, on=\"date\", how='inner')\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.4 Using Matplot <br>\n",
    "\n",
    "The Matplot library is one that allows us to create basic plots out of arrays in Python. We can use this library package to create line, scatter, and bar plots to name a few.\n",
    "\n",
    "<br>\n",
    "\n",
    "We will start by importing the `matplotlib` lib package below."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4.1 Creating Plots Out of Lists (Vectors) <br>\n",
    "\n",
    "In order to demonstrate its capabilities, let's create a simple set of variables that will be used to plot our X and Y axis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = [100,200,300,400,500,600,700,800]\n",
    "X = [2016,2017,2018,2019,2020,2021,2022,2023]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we created our variables, let's begin by plotting our data using a line plot, followed by a scatter plot."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`plt.plot()` is the command for a line graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the data\n",
    "plt.plot(X, Y)\n",
    "\n",
    "# Adding a  title to our plot\n",
    "plt.title(\"Line Plot\")\n",
    "\n",
    "# Adding labels to our plot\n",
    "plt.ylabel(\"y-axis\")\n",
    "plt.xlabel(\"x-axis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "`plt.scatter()` is the command for a scatter plot."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plotting the data\n",
    "plt.scatter(X, Y)\n",
    "\n",
    "# Adding a  title to our plot\n",
    "plt.title(\"Scatter Plot\")\n",
    "\n",
    "# Adding labels to our plot\n",
    "plt.ylabel(\"y-axis\")\n",
    "plt.xlabel(\"x-axis\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`plt.bar()` is the command for a bar plot.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plotting the data\n",
    "plt.bar(X, Y)\n",
    "\n",
    "# Adding a  title to our plot\n",
    "plt.title(\"Bar Plot\")\n",
    "\n",
    "# Adding labels to our plot\n",
    "plt.ylabel(\"y-axis\")\n",
    "plt.xlabel(\"x-axis\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4.2 Adding Additional Plot Arguments <br>\n",
    "\n",
    "Like in GGPlot, you are able to make additional adjustments to the plots we makeâ€“such as changing the color of our lines, adding markers alongside lines, and even changing the linestyle. The following links below provide information to the kinds of arguments you can give to the `plot()` function with respect to the aesthetics. <br>\n",
    "\n",
    "* [Colors available](https://i.stack.imgur.com/lFZum.png)\n",
    "* [Markers available](https://matplotlib.org/stable/api/markers_api.html)\n",
    "* [Linesytles available](https://matplotlib.org/stable/gallery/lines_bars_and_markers/linestyles.html) <br>\n",
    "\n",
    "The following code shows an example of how to integrate the arguments into the `plt.plot()` function."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plotting the data once more\n",
    "plt.plot(X, Y, color='coral', marker='o', linestyle='dashed'\n",
    "         )\n",
    "\n",
    "# Adding a  title to our plot just as before\n",
    "plt.title(\"Line Plot\")\n",
    "\n",
    "# Adding labels to our plot\n",
    "plt.ylabel(\"y-axis\")\n",
    "plt.xlabel(\"x-axis\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4.3 Plotting Variables From A DataFrame <br>\n",
    "\n",
    "The examples above show how to plot simple vectors, but what if we want to plot data from a DataFrame? We can use `.plot()` to plot specific variable from a DataFrame as well. <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "Let's start by using the COVID dataset we imported earlier."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading dataframe from a link online\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv')\n",
    "\n",
    "# Grouping DataFrame by state and cases to get the total number of COVID cases per state\n",
    "df = df.groupby(\"state\")['cases'].count()\n",
    "\n",
    "# Keeping only the first 10 states in the data frame\n",
    "df = df[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "For this example, we will be plotting the cumulative frequency distributions of COVID cases per state. Unlike the code above, we will use the `.plot()` function in a way that allows us to specify the type of plot and data objects we will be using."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plotting the COVID data\n",
    "# 'kind' tells Python to plot a bar graph\n",
    "# 'width' tells python to alter the width of the bars; default is set to 0.8\n",
    "df.plot(kind='bar', x='state', y='cases', color='y', width=0.4)\n",
    "\n",
    "# adding title\n",
    "plt.title(\"Frequency of COVID Cases Per State Plot\")\n",
    "\n",
    "# adding axis-labels\n",
    "plt.ylabel(\"Cases\")\n",
    "plt.xlabel(\"State\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.5 Using the Seaborn Library <br>\n",
    "\n",
    "While Matplot lib is a powerful library, its modularity can provide a steep learning curve. Luckily, Python offers another package that facilitates plot making. Seaborn, like Matplot, is also used for plotting graphs, and it builds on the Matplotlib, Pandas, and Numpy libraries to do so. Its simpler syntax allows users to quickly pick up on plotting and creating aesthetic graphs to display relationships of data. The remainder of the workshop lessons will mainly rely on Seaborn to produce graphs.\n",
    "\n",
    "<br>\n",
    "\n",
    "We will start by importing the `seaborn` package below."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Unlike the packages above, our program does not have seaborn internally, so we must use the `conda install` operator to download the library in order to use it. For easier downloading, remove the hash below and click on the icon that appears above the \"conda install seaborn\" line of code and click on install. After, it should be easy to import the seaborn package.\n",
    "# conda install seaborn\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To show its power, let's use a simple example where we observe the average number of yearly COVID cases in California."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Reading dataframe from a link online\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv')\n",
    "\n",
    "# Subsetting df to only include CA\n",
    "df = df[(df['state']==\"California\")]\n",
    "\n",
    "# Converting current date to datetime type\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Creating year variable out of date variable\n",
    "df['year'] = df['date'].dt.year\n",
    "\n",
    "# Organizing data even further to remove cumulative deaths per day\n",
    "df['cases_(-1)']=df['cases'].shift(1)\n",
    "df['non_cum_cases']= df['cases']-df['cases_(-1)']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following is the simplest way to plot a plot using seaborn. Like in Matplot, Seaborn allows us to produce line plots, barplots, box plots, scatter plots, kernel density plots, regression plots, etc."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.lineplot(data=df, x='year', y='non_cum_cases')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Like in Matplot, we are able to give seaborn additional arguments to make our plots more customizable. The `sns.set_style` tells Python to set a preset theme for the plot we will be using. Some of the presets that seaborn has available are: <br>\n",
    "* 'whitegrid'\n",
    "* 'darkgrid'\n",
    "* 'white'\n",
    "* 'dark'\n",
    "* 'ticks' <br>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Setting theme style\n",
    "sns.set_style('ticks')\n",
    "\n",
    "# ci as 'False' removes the confidence intervals\n",
    "# linestyle changes the style of the line\n",
    "# color changes the color of the line\n",
    "plot = sns.lineplot(data=df, x='year', y='non_cum_cases', color='y', linestyle = 'solid', ci=False)\n",
    "\n",
    "# Adding title and labels\n",
    "plot.set_title('Average COVID Cases per Year (CA)', fontdict={'size': 18, 'weight': 'normal'})\n",
    "plot.set_xlabel('Year', fontdict={'size': 12})\n",
    "plot.set_ylabel('COVID Cases (Avg)', fontdict={'size': 12})\n",
    "\n",
    "# Saving figure to your directory\n",
    "fig = plot.get_figure()\n",
    "fig.savefig('output.png')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
